{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6b5939-646c-4714-9f0a-150efe331353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f54a2-e5bc-4c0b-999d-f01d0dc6d761",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7e7fa26c-dd2e-499b-b908-0bf1db757e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer, nonlinearity='leaky_relu'):\n",
    "    '''\n",
    "    Initialize a layer\n",
    "    '''\n",
    "    #pdb.set_trace()\n",
    "    classname = layer.__class__.__name__\n",
    "    if (classname.find('Conv') != -1) or (classname.find('Linear') != -1):\n",
    "        nn.init.kaiming_uniform_(layer.weight, nonlinearity=nonlinearity)\n",
    "        if hasattr(layer, 'bias'):\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(layer.weight, 1.0, 0.02)\n",
    "        nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                kernel_size=(3,3), stride=(1,1), padding=(1,1),\n",
    "                dilation=1, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, \n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size, stride=stride,\n",
    "                    padding=padding, dilation=dilation, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=out_channels, \n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size, stride=stride,\n",
    "                    padding=padding, dilation=dilation, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for layer in self.double_conv:\n",
    "            init_layer(layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        x = self.double_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, pos_len, d_model=512, pe_type='t', dropout=0.0):\n",
    "        \"\"\" Positional encoding using sin and cos\n",
    "\n",
    "        Args:\n",
    "            pos_len: positional length\n",
    "            d_model: number of feature maps\n",
    "            pe_type: 't' | 'f' , time domain, frequency domain\n",
    "            dropout: dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pe_type = pe_type\n",
    "        pe = torch.zeros(pos_len, d_model)\n",
    "        pos = torch.arange(0, pos_len).float().unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = 0.1 * torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = 0.1 * torch.cos(pos * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(1, 2) # (N, C, T)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is (N, C, T, F) or (N, C, T) or (N, C, F)\n",
    "        if x.ndim == 4:\n",
    "            if self.pe_type == 't':\n",
    "                pe = self.pe.unsqueeze(3)\n",
    "                x += pe[:, :, :x.shape[2]]\n",
    "            elif self.pe_type == 'f':\n",
    "                pe = self.pe.unsqueeze(2)\n",
    "                x += pe[:, :, :, :x.shape[3]]\n",
    "        elif x.ndim == 3:\n",
    "            x += self.pe[:, :, :x.shape[2]]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class mACCDOA(nn.Module):\n",
    "    def __init__(self,n_track=2,n_class=13):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_track = n_track\n",
    "        self.n_class = n_class\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        self.accdoa = nn.Linear(1024,n_track*n_class*3)\n",
    "        \n",
    "        init_layer(self.accdoa)\n",
    "        \n",
    "    def forward(self, f_sed,f_doa): \n",
    "        #print(\"f_sed f_doa {} {}\".format(f_sed.shape,f_doa.shape))\n",
    "        \n",
    "        x = torch.cat((f_sed,f_doa),dim=2)\n",
    "        x = self.activation(self.accdoa(x))\n",
    "        \n",
    "        #print(\"x {}\".format(x.shape))\n",
    "        return x.reshape(x.shape[0],x.shape[1],self.n_track,self.n_class,3)\n",
    "        \n",
    "    \n",
    "class SED_DOA(nn.Module):\n",
    "    def __init__(self, n_track=3,n_class=13):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_track = n_track\n",
    "        \n",
    "        if n_track < 1 : \n",
    "            raise Exception(\"ERORR:SED_DOA:: {} < 1\".format(n_track))\n",
    "        \n",
    "        self.sed=[]\n",
    "        self.doa=[]\n",
    "        \n",
    "        self.sed_act = nn.Identity()\n",
    "        self.doa_act = nn.Tanh()\n",
    "        \n",
    "        \n",
    "        for i in range(n_track) :\n",
    "            self.sed.append(nn.Linear(512, n_class, bias=True))\n",
    "            self.doa.append(nn.Linear(512, 3, bias=True))\n",
    "        \n",
    "        for i in range(n_track) : \n",
    "            init_layer(self.sed[i])\n",
    "            init_layer(self.doa[i])\n",
    "        \n",
    "    def forward(self, f_sed, f_doa):\n",
    "        \n",
    "        sed = self.sed[0](f_sed)\n",
    "        doa = self.doa[0](f_doa)\n",
    "        \n",
    "        sed = torch.unsqueeze(sed,2)\n",
    "        doa = torch.unsqueeze(doa,2)\n",
    "        \n",
    "        #print(\"SED_DOA : {}\".format(sed.shape))\n",
    "        \n",
    "        for i in range(1,self.n_track) : \n",
    "            t_sed = self.sed[i](f_sed)\n",
    "            t_doa = self.doa[i](f_doa)\n",
    "            \n",
    "            t_sed = torch.unsqueeze(t_sed,2)\n",
    "            t_doa = torch.unsqueeze(t_doa,2)\n",
    "            \n",
    "            sed = torch.cat((sed,t_sed),2)\n",
    "            doa = torch.cat((doa,t_doa),2)\n",
    "              \n",
    "            #print(\"SED_DOA : {}\".format(sed.shape))\n",
    "            \n",
    "        return {\"sed\":sed,\"doa\":doa}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f827e6fc-24f5-43bb-b2a3-07997fee04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EINV2(nn.Module):\n",
    "    def __init__(self,\n",
    "    in_channels=4,\n",
    "    out_format=\"SED_DOA\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pe_enable = True  # Ture | False\n",
    "       \n",
    "        self.downsample_ratio = 2 ** 2\n",
    "        self.sed_conv_block1 = nn.Sequential(\n",
    "            DoubleConv(in_channels=4, out_channels=64),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
    "        )\n",
    "        self.sed_conv_block2 = nn.Sequential(\n",
    "            DoubleConv(in_channels=64, out_channels=128),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
    "        )\n",
    "        self.sed_conv_block3 = nn.Sequential(\n",
    "            DoubleConv(in_channels=128, out_channels=256),\n",
    "            nn.AvgPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "        self.sed_conv_block4 = nn.Sequential(\n",
    "            DoubleConv(in_channels=256, out_channels=512),\n",
    "            nn.AvgPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "\n",
    "        self.doa_conv_block1 = nn.Sequential(\n",
    "            DoubleConv(in_channels=in_channels, out_channels=64),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
    "        )\n",
    "        self.doa_conv_block2 = nn.Sequential(\n",
    "            DoubleConv(in_channels=64, out_channels=128),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2)),\n",
    "        )\n",
    "        self.doa_conv_block3 = nn.Sequential(\n",
    "            DoubleConv(in_channels=128, out_channels=256),\n",
    "            nn.AvgPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "        self.doa_conv_block4 = nn.Sequential(\n",
    "            DoubleConv(in_channels=256, out_channels=512),\n",
    "            nn.AvgPool2d(kernel_size=(1, 2)),\n",
    "        )\n",
    "\n",
    "        self.stitch = nn.ParameterList([\n",
    "           nn.Parameter(torch.FloatTensor(64, 2, 2).uniform_(0.1, 0.9)),\n",
    "           nn.Parameter(torch.FloatTensor(128, 2, 2).uniform_(0.1, 0.9)),\n",
    "           nn.Parameter(torch.FloatTensor(256, 2, 2).uniform_(0.1, 0.9)),\n",
    "        ])\n",
    "\n",
    "        if self.pe_enable:\n",
    "            self.sed_pe = PositionalEncoding(pos_len=100, d_model=512, pe_type='t', dropout=0.0)\n",
    "            self.doa_pe = PositionalEncoding(pos_len=100, d_model=512, pe_type='t', dropout=0.0)\n",
    "\n",
    "        decoder_layer1 = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "        decoder_layer2 = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "        self.trans_decoder_sed_doa = nn.TransformerDecoder(decoder_layer1, num_layers=2)\n",
    "        self.trans_decoder_doa_sed = nn.TransformerDecoder(decoder_layer2, num_layers=2)\n",
    "\n",
    "        self.fc_sed_track1 = nn.Linear(512, 12, bias=True)\n",
    "        self.fc_sed_track2 = nn.Linear(512, 12, bias=True)\n",
    "        self.fc_sed_track3 = nn.Linear(512, 12, bias=True)\n",
    "        self.fc_doa_track1 = nn.Linear(512, 3, bias=True)\n",
    "        self.fc_doa_track2 = nn.Linear(512, 3, bias=True)\n",
    "        self.fc_doa_track3 = nn.Linear(512, 3, bias=True)\n",
    "        self.final_act_sed = nn.Sequential() # nn.Sigmoid()\n",
    "        self.final_act_doa = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "        if out_format==\"SED_DOA\":\n",
    "            self.format = SED_DOA()\n",
    "        elif out_format == \"multi-ACCDOA\":\n",
    "            self.format = MultiACCDOA()\n",
    "        else : \n",
    "            raise Exception(\"ERROR::EINV2::unknown format {}\".format(out_format))\n",
    "    \n",
    "    def init_weight(self):\n",
    "\n",
    "        init_layer(self.fc_sed_track1)\n",
    "        init_layer(self.fc_sed_track2)\n",
    "        init_layer(self.fc_sed_track3)\n",
    "        init_layer(self.fc_doa_track1)\n",
    "        init_layer(self.fc_doa_track2)\n",
    "        init_layer(self.fc_doa_track3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: waveform, (batch_size, num_channels, data_length)\n",
    "        \"\"\"\n",
    "        #pdb.set_trace()\n",
    "        x_sed = x[:, :4] #[32,4,161,256]\n",
    "        x_doa = x\n",
    "        #x_doa = x[:, 4:]        #[32,7,161,256]   \n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # CNN\n",
    "        x_sed = self.sed_conv_block1(x_sed) #[32,64,80,128]\n",
    "        x_doa = self.doa_conv_block1(x_doa) #[32,64,80,128]\n",
    "        x_sed = torch.einsum('c, nctf -> nctf', self.stitch[0][:, 0, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[0][:, 0, 1], x_doa)\n",
    "        x_doa = torch.einsum('c, nctf -> nctf', self.stitch[0][:, 1, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[0][:, 1, 1], x_doa)\n",
    "        print(\"[1] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "        \n",
    "        x_sed = self.sed_conv_block2(x_sed) #[32,128,40,64] \n",
    "        x_doa = self.doa_conv_block2(x_doa) #[32,128,40,64]\n",
    "        x_sed = torch.einsum('c, nctf -> nctf', self.stitch[1][:, 0, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[1][:, 0, 1], x_doa)\n",
    "        x_doa = torch.einsum('c, nctf -> nctf', self.stitch[1][:, 1, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[1][:, 1, 1], x_doa)\n",
    "        print(\"[2] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "        \n",
    "        x_sed = self.sed_conv_block3(x_sed) #[32,256,40,32]\n",
    "        x_doa = self.doa_conv_block3(x_doa) #[32,256,40,32]\n",
    "        x_sed = torch.einsum('c, nctf -> nctf', self.stitch[2][:, 0, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[2][:, 0, 1], x_doa)\n",
    "        x_doa = torch.einsum('c, nctf -> nctf', self.stitch[2][:, 1, 0], x_sed) + \\\n",
    "           torch.einsum('c, nctf -> nctf', self.stitch[2][:, 1, 1], x_doa)\n",
    "        print(\"[3] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "        \n",
    "        x_sed = self.sed_conv_block4(x_sed) #[32,512,40,16]\n",
    "        x_doa = self.doa_conv_block4(x_doa) #[32,512,40,16]\n",
    "        print(\"[4] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "\n",
    "        x_sed = x_sed.mean(dim=3) # (N, C, T)\n",
    "        x_doa = x_doa.mean(dim=3) # (N, C, T) [32,512,40]\n",
    "        print(\"[5] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "\n",
    "        # Transformer\n",
    "        if self.pe_enable:\n",
    "            x_doa = self.sed_pe(x_doa)\n",
    "            x_sed = self.doa_pe(x_sed)\n",
    "        x_sed = x_sed.permute(2, 0, 1) # (T, N, C)\n",
    "        x_doa = x_doa.permute(2, 0, 1) # (T, N, C)\n",
    "        \n",
    "        print(\"[6] sed : {} | doa : {}\".format(x_sed.shape,x_doa.shape))\n",
    "\n",
    "        x_sed_trans = self.trans_decoder_sed_doa(x_sed, x_doa).transpose(0, 1)\n",
    "        x_doa_trans = self.trans_decoder_doa_sed(x_doa, x_sed).transpose(0, 1)\n",
    "        \n",
    "        \n",
    "        print(\"x_sed_trains : {}\".format(x_sed_trans.shape))\n",
    "        print(\"x_doa_trains : {}\".format(x_doa_trans.shape))\n",
    "        \n",
    "        output = self.format(x_sed_trans,x_doa_trans)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cde1a0-c4f0-4606-b487-f57b944d974d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d0c614fc-84be-4ef3-8d53-c0b578d0b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] sed : torch.Size([2, 64, 22, 63]) | doa : torch.Size([2, 64, 22, 63])\n",
      "[2] sed : torch.Size([2, 128, 11, 31]) | doa : torch.Size([2, 128, 11, 31])\n",
      "[3] sed : torch.Size([2, 256, 11, 15]) | doa : torch.Size([2, 256, 11, 15])\n",
      "[4] sed : torch.Size([2, 512, 11, 7]) | doa : torch.Size([2, 512, 11, 7])\n",
      "[5] sed : torch.Size([2, 512, 11]) | doa : torch.Size([2, 512, 11])\n",
      "[6] sed : torch.Size([11, 2, 512]) | doa : torch.Size([11, 2, 512])\n",
      "x_sed_trains : torch.Size([2, 11, 512])\n",
      "x_doa_trains : torch.Size([2, 11, 512])\n",
      "[1] sed : torch.Size([2, 64, 22, 63]) | doa : torch.Size([2, 64, 22, 63])\n",
      "[2] sed : torch.Size([2, 128, 11, 31]) | doa : torch.Size([2, 128, 11, 31])\n",
      "[3] sed : torch.Size([2, 256, 11, 15]) | doa : torch.Size([2, 256, 11, 15])\n",
      "[4] sed : torch.Size([2, 512, 11, 7]) | doa : torch.Size([2, 512, 11, 7])\n",
      "[5] sed : torch.Size([2, 512, 11]) | doa : torch.Size([2, 512, 11])\n",
      "[6] sed : torch.Size([11, 2, 512]) | doa : torch.Size([11, 2, 512])\n",
      "x_sed_trains : torch.Size([2, 11, 512])\n",
      "x_doa_trains : torch.Size([2, 11, 512])\n",
      "torch.Size([2, 11, 2, 13, 3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand((2,4, 44, 126))\n",
    "model = EINV2()\n",
    "output = model(input)\n",
    "\n",
    "model = EINV2(out_format=\"multi-ACCDOA\")\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b55ea101-ef40-44d8-86d1-ce2a7c46cc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sed', 'doa'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2721ca4-16b1-4f0b-a6ba-510aa680218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 70, 3, 13])\n",
      "torch.Size([2, 70, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(output[\"sed\"].shape)\n",
    "print(output[\"doa\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "292a93d1-9acc-42df-b074-f86f7e637766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30])\n",
      "torch.Size([30, 2])\n"
     ]
    }
   ],
   "source": [
    "qq = torch.rand(2,30)\n",
    "print(qq.shape)\n",
    "\n",
    "qq  = qq.reshape(30,2)\n",
    "print(qq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf66c72-c8a2-4c23-9761-980b022dea22",
   "metadata": {},
   "source": [
    "# Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58789a0c-60f3-4c29-9afc-f0101ee8e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db51693b-dc61-42da-8c58-6e7caa702420",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8a3627-7978-46b1-a2d0-05cfc54bb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "size shape must match input shape. Input is 1D, size is 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2980064/1305219987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3652\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3653\u001b[0m                     \u001b[0;34m\"size shape must match input shape. \"\u001b[0m \u001b[0;34m\"Input is {}D, size is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: size shape must match input shape. Input is 1D, size is 3"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,4)\n",
    "print(x.shape)\n",
    "\n",
    "y = torch.nn.functional.interpolate(input=x,size=(2,3,4))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41668a0-89da-43e9-b251-86ee2c7fa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b41862-4339-495e-8b80-de5b767592f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,4,3)\n",
    "y = torch.rand(1,5,3)\n",
    "z = torch.cat((x,y),dim=1)\n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ad7c6-bc49-43f4-91d1-82bf94a647ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
